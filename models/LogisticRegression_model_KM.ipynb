{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Information\n",
    "No. of Features: 10  \n",
    "No. of Instances: 4492  \n",
    "\n",
    "### Table of Contents<a name='table of contents'></a>\n",
    "\n",
    "1. [Data Ingestion](#data ingestion)\n",
    "2. [Features & Target Arrays](#features and target arrays)\n",
    "3. [Logistic Regression Model](#logreg)  \n",
    "    a. [Scale Data](#scale data)  \n",
    "    b. [Hyperparameter Tuning](#hyperparameter tuning)  \n",
    "    c. [Classification Report](#classification report)  \n",
    "    d. [Confusion Matrix](#confusion matrix)   \n",
    "4. [Save Model](#pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import yellowbrick as yb\n",
    "sns.set_palette('RdBu', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion<a name='data ingestion'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = 'https://raw.githubusercontent.com/georgetown-analytics/classroom-occupancy/master/models/sensor_data_ml.csv'\n",
    "\n",
    "def fetch_data(fname='sensor_data_ml.csv'):\n",
    "    response = requests.get(URL)\n",
    "    outpath  = os.path.abspath(fname)\n",
    "    with open(outpath, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    return outpath\n",
    "\n",
    "# Defining fetching data from the URL\n",
    "DATA = fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import as pandas dataframe with DateTimeIndex: df\n",
    "df = pd.read_csv('sensor_data_ml.csv', index_col='datetime', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df.columns = ['temp', 'humidity', 'co2', 'light', 'light_st', 'noise',\n",
    "              'bluetooth', 'images', 'door', 'occupancy_count', 'occupancy_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4492 entries, 2017-03-25 09:05:00 to 2017-06-10 16:47:00\n",
      "Data columns (total 11 columns):\n",
      "temp               4492 non-null float64\n",
      "humidity           4492 non-null float64\n",
      "co2                4492 non-null float64\n",
      "light              4492 non-null float64\n",
      "light_st           4492 non-null float64\n",
      "noise              4492 non-null float64\n",
      "bluetooth          4492 non-null float64\n",
      "images             4492 non-null float64\n",
      "door               4492 non-null float64\n",
      "occupancy_count    4492 non-null float64\n",
      "occupancy_level    4492 non-null object\n",
      "dtypes: float64(10), object(1)\n",
      "memory usage: 421.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>co2</th>\n",
       "      <th>light</th>\n",
       "      <th>light_st</th>\n",
       "      <th>noise</th>\n",
       "      <th>bluetooth</th>\n",
       "      <th>images</th>\n",
       "      <th>door</th>\n",
       "      <th>occupancy_count</th>\n",
       "      <th>occupancy_level</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-03-25 09:05:00</th>\n",
       "      <td>22.600000</td>\n",
       "      <td>36.900000</td>\n",
       "      <td>781.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>511.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.242697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-25 09:06:00</th>\n",
       "      <td>23.800000</td>\n",
       "      <td>38.954167</td>\n",
       "      <td>765.465279</td>\n",
       "      <td>428.533744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>503.515931</td>\n",
       "      <td>11.399457</td>\n",
       "      <td>15.242697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-25 09:07:00</th>\n",
       "      <td>23.850000</td>\n",
       "      <td>38.900000</td>\n",
       "      <td>768.458333</td>\n",
       "      <td>423.576500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>510.548913</td>\n",
       "      <td>19.916667</td>\n",
       "      <td>15.242697</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-25 09:08:00</th>\n",
       "      <td>23.900000</td>\n",
       "      <td>38.766667</td>\n",
       "      <td>777.791667</td>\n",
       "      <td>423.053571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>506.504630</td>\n",
       "      <td>29.750000</td>\n",
       "      <td>15.242697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.416667</td>\n",
       "      <td>mid-level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-25 09:09:00</th>\n",
       "      <td>23.908333</td>\n",
       "      <td>38.733333</td>\n",
       "      <td>770.864583</td>\n",
       "      <td>438.607904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500.092672</td>\n",
       "      <td>35.860577</td>\n",
       "      <td>15.242697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          temp   humidity         co2       light  light_st  \\\n",
       "datetime                                                                      \n",
       "2017-03-25 09:05:00  22.600000  36.900000  781.000000  430.000000       1.0   \n",
       "2017-03-25 09:06:00  23.800000  38.954167  765.465279  428.533744       1.0   \n",
       "2017-03-25 09:07:00  23.850000  38.900000  768.458333  423.576500       1.0   \n",
       "2017-03-25 09:08:00  23.900000  38.766667  777.791667  423.053571       1.0   \n",
       "2017-03-25 09:09:00  23.908333  38.733333  770.864583  438.607904       1.0   \n",
       "\n",
       "                          noise  bluetooth     images      door  \\\n",
       "datetime                                                          \n",
       "2017-03-25 09:05:00  511.000000   1.000000  15.242697  0.000000   \n",
       "2017-03-25 09:06:00  503.515931  11.399457  15.242697  0.000000   \n",
       "2017-03-25 09:07:00  510.548913  19.916667  15.242697  0.083333   \n",
       "2017-03-25 09:08:00  506.504630  29.750000  15.242697  0.000000   \n",
       "2017-03-25 09:09:00  500.092672  35.860577  15.242697  0.000000   \n",
       "\n",
       "                     occupancy_count occupancy_level  \n",
       "datetime                                              \n",
       "2017-03-25 09:05:00         0.000000           empty  \n",
       "2017-03-25 09:06:00         0.000000           empty  \n",
       "2017-03-25 09:07:00         4.416667             low  \n",
       "2017-03-25 09:08:00        23.416667       mid-level  \n",
       "2017-03-25 09:09:00        30.000000            high  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features & Target Arrays<a name='features and target arrays'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high         2881\n",
       "mid-level     781\n",
       "empty         482\n",
       "low           348\n",
       "Name: occupancy_level, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Breakdown of classroom occupancy levels\n",
    "df.occupancy_level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode multiclass target variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit_transform(df['occupancy_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use TimeSeriesSplit to create training and test set split indices\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "X = df.drop('occupancy_level', axis=1).values\n",
    "y = df['occupancy_level']\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=12)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression Model<a name='logreg'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Cross-Validation Scores\n",
      "[ 0.79937304  0.85579937  0.95924765  0.81818182  0.64890282  0.830721\n",
      "  0.53291536  0.94357367  0.80877743  0.7492163   0.67711599  0.94357367]\n",
      "Average 12-Fold CV Score: 0.7973\n"
     ]
    }
   ],
   "source": [
    "# Initial cross-validation scores\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Fit logistic regression classifier onto the training data: logreg\n",
    "logreg = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)\n",
    "\n",
    "# Print the 12-fold cross-validation scores\n",
    "cv_scores = cross_val_score(logreg, X_train, y_train, cv=tscv)\n",
    "\n",
    "print('Logistic Regression Cross-Validation Scores')\n",
    "print(cv_scores)\n",
    "print('Average 12-Fold CV Score: {:.4f}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      empty       1.00      0.87      0.93        61\n",
      "       high       0.97      0.99      0.98       198\n",
      "        low       0.68      1.00      0.81        41\n",
      "  mid-level       0.96      0.60      0.74        45\n",
      "\n",
      "avg / total       0.94      0.92      0.92       345\n",
      "\n",
      "Training set score: 0.8949\n",
      "Test set score: 0.9217\n"
     ]
    }
   ],
   "source": [
    "# Initial classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Compute and print the classification report and training and test scores\n",
    "print('Logistic Regression Model')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Training set score: {:.4f}'.format(logreg.score(X_train, y_train)))\n",
    "print('Test set score: {:.4f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data<a name='scale data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Scaling: 0.9913\n",
      "Accuracy without Scaling: 0.9217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Setup the pipeline with RobustScaler: steps\n",
    "steps = [('scaler', RobustScaler()),\n",
    "         ('logreg', LogisticRegression(solver='lbfgs', multi_class='multinomial'))]\n",
    "\n",
    "# Create the pipeline: pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline to the training set: logreg_scaled\n",
    "logreg_scaled = pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Instantiate and fit a logreg classifier to the unscaled data: logreg_unscaled\n",
    "logreg_unscaled = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print('Accuracy with Scaling: {:.4f}'.format(logreg_scaled.score(X_test, y_test)))\n",
    "print('Accuracy without Scaling: {:.4f}'.format(logreg_unscaled.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Cross-Validation Scores: Scaled\n",
      "[ 0.86833856  0.91222571  0.93103448  0.85893417  0.76175549  0.72727273\n",
      "  0.61442006  0.99059561  0.98746082  0.99059561  0.90909091  0.99373041]\n",
      "Average 12-Fold CV Score: 0.8788\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation scores for scaled data\n",
    "cv_scores = cross_val_score(logreg_scaled, X_train, y_train, cv=tscv)\n",
    "print('Logistic Regression Cross-Validation Scores: Scaled')\n",
    "print(cv_scores)\n",
    "print('Average 12-Fold CV Score: {:.4f}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model: Scaled\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      empty       1.00      1.00      1.00        61\n",
      "       high       1.00      1.00      1.00       198\n",
      "        low       0.93      1.00      0.96        41\n",
      "  mid-level       1.00      0.93      0.97        45\n",
      "\n",
      "avg / total       0.99      0.99      0.99       345\n",
      "\n",
      "Training set score: 0.9891\n",
      "Test set score: 0.9913\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = logreg_scaled.predict(X_test)\n",
    "\n",
    "# Compute and print the classification report and training and test scores\n",
    "print('Logistic Regression Model: Scaled')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Training set score: {:.4f}'.format(logreg_scaled.score(X_train, y_train)))\n",
    "print('Test set score: {:.4f}'.format(logreg_scaled.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning<a name='hyperparameter tuning'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\\ nPipeline(steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "       with_scaling=True)), ('logisticregression', LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
      "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
      "          tol=0.0001, verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe = make_pipeline(RobustScaler(),\n",
    "                     LogisticRegression(solver='lbfgs', multi_class='multinomial'))\n",
    "\n",
    "param_grid = {'logisticregression__C': [0.01, 0.1, 1, 10, 100, 110, 120]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=tscv)\n",
    "\n",
    "logreg_clf = grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best estimator:\\ n{}'.format(logreg_clf.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model (Hypertuned)\n",
      "Best cross-validation accuracy: 0.9378\n",
      "Test set score: 0.9942\n",
      "Best parameters: {'logisticregression__C': 100}\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Model (Hypertuned)')\n",
    "print('Best cross-validation accuracy: {:.4f}'.format(logreg_clf.best_score_))\n",
    "print('Test set score: {:.4f}'.format(logreg_clf.score(X_test, y_test)))\n",
    "print('Best parameters: {}'.format(logreg_clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression coefficients:\\ n[[  1.34545398e-01  -3.22510416e-01  -1.17065056e+00   5.28899360e-01\n",
      "    3.53873454e+00  -1.10973335e+00  -5.29392868e-01   2.82714770e-01\n",
      "   -1.11748443e-01  -3.55673512e+01]\n",
      " [ -1.77820099e-01   5.24521962e-01   1.83219648e+00  -2.46018015e-01\n",
      "   -2.32100742e+00   2.44918998e+00   9.68101884e-03  -4.93399108e-01\n",
      "    1.11157086e-01   7.24321416e+01]\n",
      " [ -8.07061869e-02  -1.95847907e-01   6.07258288e-02  -1.26072416e-01\n",
      "    1.12450200e-01  -3.92625574e-01   1.63648787e-01   7.18097248e-02\n",
      "   -1.20948344e-01  -2.59175950e+01]\n",
      " [  1.23980888e-01  -6.16363920e-03  -7.22271743e-01  -1.56808929e-01\n",
      "   -1.33017731e+00  -9.46831053e-01   3.56063062e-01   1.38874613e-01\n",
      "    1.21539701e-01  -1.09471954e+01]]\n"
     ]
    }
   ],
   "source": [
    "print('Logistic regression coefficients:\\ n{}'.format(logreg_clf.best_estimator_.named_steps['logisticregression'].coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report<a name='classification report'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      empty       1.00      1.00      1.00        61\n",
      "       high       1.00      1.00      1.00       198\n",
      "        low       0.95      1.00      0.98        41\n",
      "  mid-level       1.00      0.96      0.98        45\n",
      "\n",
      "avg / total       0.99      0.99      0.99       345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = logreg_clf.predict(X_test)\n",
    "\n",
    "# Compute and print the classification report and training and test scores\n",
    "print('Logistic Regression Model')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix <a name='confusion matrix'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Confusion Matrix\n",
      "[[ 61   0   0   0]\n",
      " [  0 198   0   0]\n",
      " [  0   0  41   0]\n",
      " [  0   0   2  43]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Logistic Regression Confusion Matrix')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model<a name='pickle'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "logreg_model = 'logreg_model.sav'\n",
    "\n",
    "# Save fitted model to disk\n",
    "pickle.dump(logreg_clf, open(logreg_model, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Return to Table of Contents](#table of contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
